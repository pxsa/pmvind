{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import hmean\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Segment Type</th>\n",
       "      <th>Segment Description</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>548</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>916</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>86</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>179</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>None</td>\n",
       "      <td>947</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question Segment Type  \\\n",
       "0  What social platform has influenced your onlin...       Mobile   \n",
       "1  What social platform has influenced your onlin...       Mobile   \n",
       "2  What social platform has influenced your onlin...       Mobile   \n",
       "3  What social platform has influenced your onlin...       Mobile   \n",
       "4  What social platform has influenced your onlin...       Mobile   \n",
       "\n",
       "  Segment Description     Answer  Count  Percentage  \n",
       "0      Global results   Facebook    548       0.205  \n",
       "1      Global results  Instagram    916       0.342  \n",
       "2      Global results   Snapchat     86       0.032  \n",
       "3      Global results    Twitter    179       0.067  \n",
       "4      Global results       None    947       0.354  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"data/Students_Performance_mv.csv\")\n",
    "df = pd.read_csv(\"data/WhatsgoodlyData-6.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop numerical columns\n",
    "# df.drop(columns=['math score','reading score','writing score'], inplace=True)\n",
    "df.drop(columns=['Count','Percentage'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question               0\n",
       "Segment Type           0\n",
       "Segment Description    0\n",
       "Answer                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of missing values per column.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Question', 'Segment Type', 'Segment Description', 'Answer'], dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Segment Type</th>\n",
       "      <th>Segment Description</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>Snapchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global results</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Global results</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "      <td>Snapchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What social platform has influenced your onlin...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question Segment Type  \\\n",
       "0  What social platform has influenced your onlin...       Mobile   \n",
       "1  What social platform has influenced your onlin...       Mobile   \n",
       "2  What social platform has influenced your onlin...       Mobile   \n",
       "3  What social platform has influenced your onlin...          NaN   \n",
       "4  What social platform has influenced your onlin...       Mobile   \n",
       "5  What social platform has influenced your onlin...          Web   \n",
       "6  What social platform has influenced your onlin...          Web   \n",
       "7  What social platform has influenced your onlin...          Web   \n",
       "8  What social platform has influenced your onlin...          Web   \n",
       "9  What social platform has influenced your onlin...          Web   \n",
       "\n",
       "  Segment Description     Answer  \n",
       "0      Global results        NaN  \n",
       "1      Global results  Instagram  \n",
       "2      Global results   Snapchat  \n",
       "3      Global results    Twitter  \n",
       "4      Global results       None  \n",
       "5                 Web   Facebook  \n",
       "6                 NaN        NaN  \n",
       "7                 Web   Snapchat  \n",
       "8                 Web    Twitter  \n",
       "9                 Web       None  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nullify some fields at random\n",
    "df = df.stack().sample(frac=0.9).unstack()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question               149\n",
       "Segment Type           138\n",
       "Segment Description    132\n",
       "Answer                 161\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCompleteTuples(df):\n",
    "    # getting the rows without null values\n",
    "    CT = df.dropna()\n",
    "    return CT   # CT.shape #(959, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractInCompleteTuples(df):\n",
    "    # getting only the rows with null values\n",
    "    ICT = df[df.isnull().any(axis=1)]\n",
    "    # print(ICT.shape) #(41, 5)\n",
    "    return ICT.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log,e\n",
    "\n",
    "# Entropy weight method (EWM)\n",
    "def ComputeAttributeWeights(CT):\n",
    "    n = CT.shape[0] # the number of rows in complete tuples\n",
    "    s = CT.shape[1] # the number of columns\n",
    "\n",
    "    # 1- Normalizing data(just numerocal cols)\n",
    "\n",
    "    # 2-1 Calculating the entropy of each numerical attribute   \n",
    "    \n",
    "    # 2-2 Calculating the entropy of each categorical attribute \n",
    "    def entropy(labels, base=None):\n",
    "        vc = pd.Series(labels).value_counts(normalize=True, sort=False)\n",
    "        base = e if base is None else base\n",
    "        return -(vc * np.log(vc)/np.log(base)).sum()\n",
    "\n",
    "    E = []          # [0.6924027159890356, 1.5185039737243646, 1.71940544072419, 0.6502094546756849, 0.6508318554230292]\n",
    "    for column in CT:\n",
    "        E.append(entropy(CT[column], base=None))\n",
    "    # 3- Determining the weight of each attribute\n",
    "    w = [0] * s     # [-1.3295556932195063, 2.241176844063399, 3.1095515115596424, -1.5119314608568568, -1.5092412015466796]\n",
    "    # TODO what is k?\n",
    "    k = s\n",
    "    sum = 0\n",
    "    for i in range(k):\n",
    "        sum += E[i]\n",
    "\n",
    "    for i in range(s):\n",
    "        w[i] = (1 - E[i]) / (k - sum)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SortInCompleteTuples(ICT, r):\n",
    "    # Convert list to npArray\n",
    "    r = np.array(r)\n",
    "\n",
    "    # Arg sort\n",
    "    argSort = np.argsort(r) # it sorts r, and returns corresponding indexes\n",
    "    \n",
    "    # Create new empty npArray for sorted ICT\n",
    "    sortedICT = np.copy(ICT)\n",
    "    for index in range(argSort.size):\n",
    "        sortedICT[index] = ICT[argSort[index]]\n",
    "    \n",
    "    return sortedICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Partition(seq, num):\n",
    "    avg  = len(seq) / float(num)\n",
    "    out  = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTuplePartition(sortedICT, m):\n",
    "    T = []\n",
    "    T = Partition(sortedICT, m)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [1] * inCompleteRowsCount\n",
    "def GenerateTuplePartitions(ICT, CT, m, s):\n",
    "\n",
    "    W = ComputeAttributeWeights(CT)\n",
    "    # STEP 1\n",
    "    # Calculate tuple integrity rate, according to DEFINITION 5(example)\n",
    "    inCompleteRowsCount = ICT.shape[0]      # the number of ICT rows                     \n",
    "    for i in range(inCompleteRowsCount):\n",
    "        for j in range(s):\n",
    "            if pd.isnull(ICT[i][j]):\n",
    "                r[i] = r[i] - W[j]    \n",
    "    # TODO  r (-4.350728355623041, 2.511931460856857) ?      \n",
    "\n",
    "    # STEP 2\n",
    "    # sort ICT's tuples according to their integrity rate\n",
    "    sortedICT = SortInCompleteTuples(ICT, r)\n",
    "    \n",
    "    # STEP 3\n",
    "    tuplePartitions = GenerateTuplePartition(sortedICT, m)\n",
    "    return tuplePartitions # a queue of subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which calculates euclidean distance between two data points(numerical)\n",
    "def euclideanDistance(data1, data2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += np.square(data1[x] - data2[x])\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(complete_set,incomplete_set, numeric_distance = \"euclidean\", categorical_distance = \"hamming\"):\n",
    "    \n",
    "    # Get the type of each attribute (Numeric or categorical)\n",
    "    is_numeric = [all(isinstance(n, numbers.Number) for n in complete_set.iloc[:, i]) for i, x in enumerate(complete_set)]\n",
    "    is_all_categorical = sum(is_numeric) == 0\n",
    "\n",
    "    if categorical_distance == 'hamming':\n",
    "        complete_set = pd.DataFrame([pd.factorize(complete_set[x])[0] for x in complete_set]).transpose()\n",
    "        incomplete_set = pd.DataFrame([pd.factorize(incomplete_set[x])[0] for x in incomplete_set]).transpose()\n",
    "\n",
    "    if is_all_categorical:\n",
    "        if categorical_distance == \"hamming\":\n",
    "            result_matrix = cdist(complete_set, incomplete_set, metric=categorical_distance)\n",
    "\n",
    "    return pd.DataFrame(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(complete_set, incomplete_set, k_neighbors, aggregation_method=\"mode\", numeric_distance=\"euclidean\",\n",
    "               categorical_distance=\"hamming\"):\n",
    "    \n",
    "    numberOfICSamples=len(incomplete_set)\n",
    "    target=[]\n",
    "    inc_set=incomplete_set.copy()\n",
    "    \n",
    "    # Make sure the data are in the right format\n",
    "    inc_set = pd.DataFrame(inc_set)\n",
    "    complete_set = pd.DataFrame(complete_set)\n",
    "    \n",
    "    # Get the distance matrix and check whether no error was triggered when computing it\n",
    "    distances = distance_matrix(complete_set,inc_set, numeric_distance, categorical_distance)\n",
    "\n",
    "    # Get the closest points and compute the correct aggregation method\n",
    "    for j in range(numberOfICSamples):\n",
    "        for i, value in enumerate(inc_set.iloc[j, :]):\n",
    "            if pd.isnull(value):\n",
    "                order = distances.iloc[:,i].values.argsort()[:k_neighbors]\n",
    "                closest_to_target = complete_set.iloc[order, i]\n",
    "                inc_set.iloc[j,i]=stats.mode(closest_to_target)[0][0]\n",
    "    \n",
    "#     target=inc_set\n",
    "    return inc_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNImputation(train_set, test_set):\n",
    "    return knn_impute(train_set, test_set, k_neighbors=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge(a, b):\n",
    "    a=np.array(a)\n",
    "    b=np.array(b)\n",
    "    return np.concatenate((a, b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mean(a, b):\n",
    "    # print(a)\n",
    "    # print(b)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin\n",
    "CT  = ExtractCompleteTuples(df)   # this is dataframe\n",
    "ICT = ExtractInCompleteTuples(df) # this is npArray\n",
    "\n",
    "# The number of partitions\n",
    "m = 5 # TODO ?\n",
    "# The number of attributes\n",
    "s = df.columns.size\n",
    "\n",
    "T = GenerateTuplePartitions(ICT, CT, m, s)\n",
    "\n",
    "CTS    = [[0]] * (m+1)\n",
    "Tp     = [[0]] * (m+1)\n",
    "CTS[0] = np.array(CT.copy())\n",
    "\n",
    "for i in range(1, m+1):\n",
    "    Tp[i-1] = KNNImputation(CTS[i-1], T[i-1])\n",
    "    CTS[i]  = Merge(CTS[i-1], Tp[i-1])\n",
    "\n",
    "\n",
    "# Do cross validation\n",
    "Tpp = [[0]] * (m+1)\n",
    "for i in range(0, m):\n",
    "    Tpp[i] = KNNImputation(train_set=CTS[m], test_set=T[i])\n",
    "\n",
    "Tpp[m] = KNNImputation(train_set=CTS[0], test_set=T[m-1])    \n",
    "\n",
    "for i in range(1, m+1):\n",
    "    CTS[i] = Merge(CTS[i-1],Tpp[i-1])\n",
    "\n",
    "# print(CTS[m].shape) #(1450, 4)\n",
    "\n",
    "# D' = CT[m] is our complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1450, 4), indices imply (1450, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# convert CTS[m] to a dataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCTS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrace/ethnicity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparental level of education\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlunch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest preparation course\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# df = df.dropna()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1450, 4), indices imply (1450, 5)"
     ]
    }
   ],
   "source": [
    "# convert CTS[m] to a dataFrame\n",
    "df = pd.DataFrame(CTS[m], columns=['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course'])\n",
    "# df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question               149\n",
       "Segment Type           138\n",
       "Segment Description    132\n",
       "Answer                 161\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of missing values per column.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gender'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m]                      \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace/ethnicity\u001b[39m\u001b[38;5;124m'\u001b[39m]              \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace/ethnicity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup A\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup B\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup C\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup D\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup E\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m4\u001b[39m})\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparental level of education\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparental level of education\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbachelor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms degree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh school\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msome college\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms degree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massociate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms degree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msome high school\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m5\u001b[39m})\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gender'"
     ]
    }
   ],
   "source": [
    "df['gender']                      = df['gender'].map({'male':0, 'female':1})\n",
    "df['race/ethnicity']              = df['race/ethnicity'].map({'group A':0, 'group B':1, 'group C':2, 'group D':3, 'group E':4})\n",
    "df['parental level of education'] = df['parental level of education'].map({\"bachelor's degree\":0, \"high school\":1, \"some college\":2, \"master's degree\":3, \"associate's degree\":4, \"some high school\":5})\n",
    "df['lunch']                       = df['lunch'].map({'standard':0, 'free/reduced':1})\n",
    "df['test preparation course']     = df['test preparation course'].map({'none':0, 'completed':1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(df['gender'])\n",
    "data   = np.array(df.loc[:, df.columns != 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 3\u001b[0m xTrain, xTest, yTrain, yTest \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m, target, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of train data:   \u001b[39m\u001b[38;5;124m\"\u001b[39m, xTrain\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of test  data:   \u001b[39m\u001b[38;5;124m\"\u001b[39m, xTest\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(data, target, random_state=42)\n",
    "\n",
    "\n",
    "print(\"shape of train data:   \", xTrain.shape)\n",
    "print(\"shape of test  data:   \", xTest.shape)\n",
    "print(\"shape of train target: \", yTest.shape)\n",
    "print(\"shape of test  target: \", yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [87]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      2\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier()\n\u001b[1;32m----> 3\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(\u001b[43mxTrain\u001b[49m, yTrain)\n\u001b[0;32m      5\u001b[0m yPred \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(xTest)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(knn\u001b[38;5;241m.\u001b[39mscore(xTrain, yTrain))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xTrain' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = knn.predict(xTest)\n",
    "print(knn.score(xTrain, yTrain))\n",
    "print(knn.score(xTest,  yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yTest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [88]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43myTest\u001b[49m, yPred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yTest' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yTest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [89]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43myTest\u001b[49m, yPred)\n\u001b[0;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, square\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yTest' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(yTest, yPred)\n",
    "sns.heatmap(cm, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PFC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PFC(NTrue, NFalse):\n",
    "    return (NFalse/(NTrue+NFalse))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractOriginalSet(df_with_NaN,df_without_NaN):\n",
    "     return np.array(df_without_NaN[df_with_NaN.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractPredictSet():\n",
    "    return CTS[m][len(CT):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of correct and incorrect predictions\n",
    "def Calculate_NT_and_NF_of_prediction(originalSet,predictSet,NaNSet):\n",
    "    NTrue=0\n",
    "    NFalse=0\n",
    "    rowsCount=len(NaNSet)\n",
    "    columnsCount=len(NaNSet[0])\n",
    "    \n",
    "    for i in range(rowsCount):\n",
    "        for j in range(columnsCount):\n",
    "            if pd.isnull(NaNSet[i][j]):\n",
    "                if(originalSet[i][j]==predictSet[i][j]):\n",
    "                    NTrue+=1\n",
    "                else:\n",
    "                    NFalse+=1\n",
    "    return {\n",
    "        \"NTrue\":NTrue,\n",
    "        \"NFalse\":NFalse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SortOriginalSet(originalSet):\n",
    "    W = ComputeAttributeWeights(CT)\n",
    "\n",
    "    inCompleteRowsCount = ICT.shape[0]     \n",
    "    r = [1] * inCompleteRowsCount                      \n",
    "    for i in range(inCompleteRowsCount):\n",
    "        for j in range(s):\n",
    "            if pd.isnull(ICT[i][j]):\n",
    "                r[i] = r[i] - W[j]    \n",
    "    \n",
    "    sortedOriginalSet = SortInCompleteTuples(originalSet, r)   \n",
    "    \n",
    "    return sortedOriginalSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SortNaNSet():\n",
    "    sortedNanSet=[0]* (len(ICT))\n",
    "    index=0\n",
    "    for i in range(len(T)):\n",
    "        for j in range(len(T[i])):\n",
    "            sortedNanSet[index]=T[i][j]\n",
    "            index+=1\n",
    "    return sortedNanSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5706896551724138\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data/WhatsgoodlyData-6.csv\")\n",
    "df2.drop(columns=['Count','Percentage'], inplace=True)\n",
    "\n",
    "originalSet=ExtractOriginalSet(df,df2)\n",
    "originalSet=SortOriginalSet(originalSet)\n",
    "\n",
    "predictSet=ExtractPredictSet()\n",
    "\n",
    "NaNSet=SortNaNSet()\n",
    "\n",
    "result=Calculate_NT_and_NF_of_prediction(originalSet,predictSet,NaNSet)\n",
    "NTrue=result.get(\"NTrue\")\n",
    "NFalse=result.get(\"NFalse\")\n",
    "\n",
    "print(PFC(NTrue,NFalse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b25c3272fda9386675e7f647d3dda333e487e678f3dc1b6bfbf79265cfda035"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
