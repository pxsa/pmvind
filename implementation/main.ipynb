{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import hmean\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Students_Performance_mv.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop numerical columns\n",
    "df.drop(columns=['math score','reading score','writing score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                          0\n",
       "race/ethnicity                 11\n",
       "parental level of education    21\n",
       "lunch                          12\n",
       "test preparation course         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of missing values per column.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'race/ethnicity', 'parental level of education', 'lunch',\n",
       "       'test preparation course'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCompleteTuples(df):\n",
    "    # getting the rows without null values\n",
    "    CT = df.dropna()\n",
    "    return CT   # CT.shape #(959, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractInCompleteTuples(df):\n",
    "    # getting only the rows with null values\n",
    "    ICT = df[df.isnull().any(axis=1)]\n",
    "    # print(ICT.shape) #(41, 5)\n",
    "    return ICT.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log,e\n",
    "\n",
    "# Entropy weight method (EWM)\n",
    "def ComputeAttributeWeights(CT):\n",
    "    n = CT.shape[0] # the number of rows in complete tuples\n",
    "    s = CT.shape[1] # the number of columns\n",
    "\n",
    "    # 1- Normalizing data(just numerocal cols)\n",
    "\n",
    "    # 2-1 Calculating the entropy of each numerical attribute   \n",
    "    \n",
    "    # 2-2 Calculating the entropy of each categorical attribute \n",
    "    def entropy(labels, base=None):\n",
    "        vc = pd.Series(labels).value_counts(normalize=True, sort=False)\n",
    "        base = e if base is None else base\n",
    "        return -(vc * np.log(vc)/np.log(base)).sum()\n",
    "\n",
    "    E = []          # [0.6924027159890356, 1.5185039737243646, 1.71940544072419, 0.6502094546756849, 0.6508318554230292]\n",
    "    for column in CT:\n",
    "        E.append(entropy(CT[column], base=None))\n",
    "    # 3- Determining the weight of each attribute\n",
    "    w = [0] * s     # [-1.3295556932195063, 2.241176844063399, 3.1095515115596424, -1.5119314608568568, -1.5092412015466796]\n",
    "    # TODO what is k?\n",
    "    k = s\n",
    "    sum = 0\n",
    "    for i in range(k):\n",
    "        sum += E[i]\n",
    "\n",
    "    for i in range(s):\n",
    "        w[i] = (1 - E[i]) / (k - sum)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SortInCompleteTuples(ICT, r):\n",
    "    # Convert list to npArray\n",
    "    r = np.array(r)\n",
    "\n",
    "    # Arg sort\n",
    "    argSort = np.argsort(r) # it sorts r, and returns corresponding indexes\n",
    "    \n",
    "    # Create new empty npArray for sorted ICT\n",
    "    sortedICT = np.copy(ICT)\n",
    "    for index in range(argSort.size):\n",
    "        sortedICT[index] = ICT[argSort[index]]\n",
    "    \n",
    "    return sortedICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Partition(seq, num):\n",
    "    avg  = len(seq) / float(num)\n",
    "    out  = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTuplePartition(sortedICT, m):\n",
    "    T = []\n",
    "    T = Partition(sortedICT, m)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTuplePartitions(ICT, CT, m, s):\n",
    "\n",
    "    W = ComputeAttributeWeights(CT)\n",
    "    # STEP 1\n",
    "    # Calculate tuple integrity rate, according to DEFINITION 5(example)\n",
    "    inCompleteRowsCount = ICT.shape[0]      # the number of ICT rows\n",
    "    r = [1] * inCompleteRowsCount                      \n",
    "    for i in range(inCompleteRowsCount):\n",
    "        for j in range(s):\n",
    "            if pd.isnull(ICT[i][j]):\n",
    "                r[i] = r[i] - W[j]    \n",
    "    # TODO  r (-4.350728355623041, 2.511931460856857) ?      \n",
    "\n",
    "    # STEP 2\n",
    "    # sort ICT's tuples according to their integrity rate\n",
    "    sortedICT = SortInCompleteTuples(ICT, r)\n",
    "    \n",
    "    # STEP 3\n",
    "    tuplePartitions = GenerateTuplePartition(sortedICT, m)\n",
    "    return tuplePartitions # a queue of subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which calculates euclidean distance between two data points(numerical)\n",
    "def euclideanDistance(data1, data2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += np.square(data1[x] - data2[x])\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_hamming(data):\n",
    "    categories_dist = []\n",
    "    \n",
    "    for category in data:\n",
    "        X = pd.get_dummies(data[category])\n",
    "        X_mean = X * X.mean()\n",
    "        X_dot = X_mean.dot(X.transpose())\n",
    "        X_np = np.asarray(X_dot.replace(0,1,inplace=False))\n",
    "        categories_dist.append(X_np)\n",
    "        \n",
    "    categories_dist = np.array(categories_dist)\n",
    "    distances = hmean(categories_dist, axis=0)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(data, numeric_distance = \"euclidean\", categorical_distance = \"jaccard\"):\n",
    "    number_of_variables = data.shape[1]\n",
    "    number_of_observations = data.shape[0]\n",
    "\n",
    "    # Get the type of each attribute (Numeric or categorical)\n",
    "    is_numeric = [all(isinstance(n, numbers.Number) for n in data.iloc[:, i]) for i, x in enumerate(data)]\n",
    "    is_all_categorical = sum(is_numeric) == 0\n",
    "\n",
    "    # Replace missing values with mode for categorical columns\n",
    "    for x in data:\n",
    "        data[x].fillna(data[x].mode()[0], inplace=True)\n",
    "\n",
    "    # \"Dummifies\" categorical variables in place\n",
    "    if not (categorical_distance == 'hamming' or categorical_distance == 'weighted-hamming'):\n",
    "        data = pd.get_dummies(data)\n",
    "    elif categorical_distance == 'hamming':\n",
    "        data = pd.DataFrame([pd.factorize(data[x])[0] for x in data]).transpose()\n",
    "\n",
    "    if is_all_categorical:\n",
    "        if categorical_distance == \"weighted-hamming\":\n",
    "            result_matrix = weighted_hamming(data)\n",
    "        else:\n",
    "            result_matrix = cdist(data, data, metric=categorical_distance)\n",
    "\n",
    "    # Fill the diagonal with NaN values\n",
    "    np.fill_diagonal(result_matrix, np.nan)\n",
    "    return pd.DataFrame(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(target, attributes, k_neighbors, aggregation_method=\"mode\", numeric_distance=\"euclidean\",\n",
    "               categorical_distance=\"jaccard\", missing_neighbors_threshold = 0.5):\n",
    "    \n",
    "    number_observations = len(target)\n",
    "    is_target_numeric = all(isinstance(n, numbers.Number) for n in target)\n",
    "    numberOfSamples=len(target[0])\n",
    "   \n",
    "    # Make sure the data are in the right format\n",
    "    target = pd.DataFrame(target)\n",
    "    attributes = pd.DataFrame(attributes)\n",
    "    \n",
    "    # Get the distance matrix and check whether no error was triggered when computing it\n",
    "    distances = distance_matrix(attributes.transpose(), numeric_distance, categorical_distance)\n",
    "\n",
    "    # Get the closest points and compute the correct aggregation method\n",
    "    for j in range(numberOfSamples):\n",
    "        for i, value in enumerate(target.iloc[:, j]):\n",
    "            if pd.isnull(value):\n",
    "                order = distances.iloc[i,:].values.argsort()[:k_neighbors]\n",
    "                closest_to_target = attributes.iloc[i, order]\n",
    "                target.iloc[i,j]=stats.mode(closest_to_target)[0][0]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNImputation(train_set, test_set):\n",
    "    knn_impute(test_set.transpose(),train_set.transpose(), k_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge(a, b):\n",
    "    a=np.array(a)\n",
    "    b=np.array(b)\n",
    "    return np.concatenate((a, b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['female' 'group B' \"bachelor's degree\" 'standard' 'none']\n",
      " ['female' 'group C' 'some college' 'standard' 'completed']\n",
      " ['female' 'group B' \"master's degree\" 'standard' 'none']\n",
      " ...\n",
      " ['female' 'group E' \"associate's degree\" nan 'none']\n",
      " ['female' 'group B' \"bachelor's degree\" nan 'none']\n",
      " ['female' 'group E' 'some college' nan 'completed']]\n"
     ]
    }
   ],
   "source": [
    "# Begin\n",
    "CT  = ExtractCompleteTuples(df)   # this is dataframe\n",
    "ICT = ExtractInCompleteTuples(df) # this is npArray\n",
    "\n",
    "# The number of partitions\n",
    "m = 5 # TODO ?\n",
    "# The number of attributes\n",
    "s = df.columns.size    # 5\n",
    "\n",
    "T = GenerateTuplePartitions(ICT, CT, m, s)\n",
    "\n",
    "# print(T[1])\n",
    "\n",
    "CTS    = [[0]] * (m)\n",
    "CTS[0] = np.array(CT.copy())\n",
    "\n",
    "for i in range(1, m):\n",
    "    KNNImputation(CTS[i-1], T[i])\n",
    "    CTS[i] =  Merge(CTS[i-1], T[i])\n",
    "\n",
    "KNNImputation(CTS[0], T[1])\n",
    "CTS[1] = Merge(CTS[0], T[1])\n",
    "    \n",
    "print(np.array(CTS[m-1]))   \n",
    "\n",
    "\n",
    "\n",
    "# Do cross validation\n",
    "# for i in range(1, m-1):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b25c3272fda9386675e7f647d3dda333e487e678f3dc1b6bfbf79265cfda035"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
